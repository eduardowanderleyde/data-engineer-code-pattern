{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7iPEfjCY6pi5",
      "metadata": {
        "id": "7iPEfjCY6pi5"
      },
      "source": [
        "##  Identifying and Correcting Invalid Data\n",
        "Strategies for Identifying Invalid Data\n",
        "1. Initial Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6d8170e6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandera\n",
            "  Downloading pandera-0.26.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from pandera) (23.2)\n",
            "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.11/site-packages (from pandera) (2.9.2)\n",
            "Collecting typeguard (from pandera)\n",
            "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: typing_extensions in /opt/anaconda3/lib/python3.11/site-packages (from pandera) (4.12.2)\n",
            "Requirement already satisfied: typing_inspect>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pandera) (0.9.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from typing_inspect>=0.6.0->pandera) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic->pandera) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic->pandera) (2.23.4)\n",
            "Collecting typing_extensions (from pandera)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Downloading pandera-0.26.1-py3-none-any.whl (292 kB)\n",
            "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Installing collected packages: typing_extensions, typeguard, pandera\n",
            "\u001b[2K  Attempting uninstall: typing_extensions\n",
            "\u001b[2K    Found existing installation: typing_extensions 4.12.2\n",
            "\u001b[2K    Uninstalling typing_extensions-4.12.2:\n",
            "\u001b[2K      Successfully uninstalled typing_extensions-4.12.232m0/3\u001b[0m [typing_extensions]\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandera]m2/3\u001b[0m [pandera]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastapi 0.104.1 requires anyio<4.0.0,>=3.7.1, but you have anyio 4.6.2.post1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandera-0.26.1 typeguard-4.4.4 typing_extensions-4.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "211a7160",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          idade      salario\n",
            "count  50.00000    50.000000\n",
            "mean   40.40000  2477.941604\n",
            "std    17.88398  1492.588455\n",
            "min    -1.00000  -500.000000\n",
            "25%    35.25000  1570.100894\n",
            "50%    45.50000  2309.607819\n",
            "75%    50.75000  3687.221923\n",
            "max    64.00000  4927.363553\n",
            "idade      0\n",
            "salario    0\n",
            "email      0\n",
            "dtype: int64\n",
            "idade        int64\n",
            "salario    float64\n",
            "email       object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pandera as pa\n",
        "\n",
        "# Loading data\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Basic statistics\n",
        "print(df.describe())\n",
        "\n",
        "# Checking for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Checking data types\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85808e60",
      "metadata": {},
      "source": [
        "### 2. Validation with Pandera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "96f38d8d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Errors found: column 'age' not in dataframe. Columns in dataframe: ['idade', 'salario', 'email']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/pandera/_pandas_deprecated.py:149: FutureWarning: Importing pandas-specific classes and functions from the\n",
            "top-level pandera module will be **removed in a future version of pandera**.\n",
            "If you're using pandera to validate pandas objects, we highly recommend updating\n",
            "your import:\n",
            "\n",
            "```\n",
            "# old import\n",
            "import pandera as pa\n",
            "\n",
            "# new import\n",
            "import pandera.pandas as pa\n",
            "```\n",
            "\n",
            "If you're using pandera to validate objects from other compatible libraries\n",
            "like pyspark or polars, see the supported libraries section of the documentation\n",
            "for more information on how to import pandera:\n",
            "\n",
            "https://pandera.readthedocs.io/en/stable/supported_libraries.html\n",
            "\n",
            "To disable this warning, set the environment variable:\n",
            "\n",
            "```\n",
            "export DISABLE_PANDERA_IMPORT_WARNING=True\n",
            "```\n",
            "\n",
            "  warnings.warn(_future_warning, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Defining validation schema\n",
        "schema = pa.DataFrameSchema({\n",
        "    'age': pa.Column(int, checks=pa.Check.ge(0)),\n",
        "    'salary': pa.Column(float, checks=pa.Check.gt(0)),\n",
        "    'email': pa.Column(str, checks=pa.Check.str_matches(r'^[^@]+@[^@]+\\.[^@]+$'))\n",
        "})\n",
        "\n",
        "# Validating and catching errors\n",
        "try:\n",
        "    schema.validate(df)\n",
        "except pa.errors.SchemaError as e:\n",
        "    print(f\"Errors found: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c111505a",
      "metadata": {},
      "source": [
        "### Data Correction Techniques\n",
        "1. Handling Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3d95f8cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Strategies for handling missing values\n",
        "def handle_missing_values(df):\n",
        "    # Fill with mean value\n",
        "    df['age'] = df['age'].fillna(df['age'].mean())\n",
        "    \n",
        "    # Fill with most frequent value\n",
        "    df['department'] = df['department'].fillna(df['department'].mode()[0])\n",
        "    \n",
        "    # Fill with a specific value\n",
        "    df['status'] = df['status'].fillna('pending')\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "610bd750",
      "metadata": {},
      "source": [
        "## 2. Data Type Correction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fa425f42",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fix_types(df):\n",
        "    # Converting string to datetime\n",
        "    df['birth_date'] = pd.to_datetime(df['birth_date'], errors='coerce')\n",
        "    \n",
        "    # Converting string to numeric\n",
        "    df['salary'] = pd.to_numeric(df['salary'], errors='coerce')\n",
        "    \n",
        "    # Converting to category\n",
        "    df['department'] = df['department'].astype('category')\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb462602",
      "metadata": {},
      "source": [
        "### 3. Correcting Invalid Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "88df95fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fix_values(df):\n",
        "    # Replacing negative values\n",
        "    df.loc[df['age'] < 0, 'age'] = df['age'].mean()\n",
        "    \n",
        "    # Fixing invalid emails\n",
        "    df.loc[~df['email'].str.contains('@', na=False), 'email'] = None\n",
        "    \n",
        "    # Limiting extreme values\n",
        "    df.loc[df['salary'] > 1_000_000, 'salary'] = 1_000_000\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6987e9b0",
      "metadata": {},
      "source": [
        "### Validation and Correction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6f7d9c7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation_correction_pipeline(df):\n",
        "    # 1. Initial analysis\n",
        "    print(\"Initial analysis:\")\n",
        "    print(df.info())\n",
        "    \n",
        "    # 2. Handling missing values\n",
        "    df = handle_missing_values(df)\n",
        "    \n",
        "    # 3. Fixing data types\n",
        "    df = fix_types(df)\n",
        "    \n",
        "    # 4. Fixing invalid values\n",
        "    df = fix_values(df)\n",
        "    \n",
        "    # 5. Final validation\n",
        "    try:\n",
        "        schema.validate(df)\n",
        "        print(\"Data successfully validated!\")\n",
        "    except pa.errors.SchemaError as e:\n",
        "        print(f\"There are still errors: {e}\")\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39b581b6",
      "metadata": {},
      "source": [
        "### Complete Practical Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1bc0a589",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial analysis:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 6 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   id          5 non-null      int64  \n",
            " 1   name        4 non-null      object \n",
            " 2   age         4 non-null      float64\n",
            " 3   salary      5 non-null      object \n",
            " 4   email       4 non-null      object \n",
            " 5   department  4 non-null      object \n",
            "dtypes: float64(1), int64(1), object(4)\n",
            "memory usage: 372.0+ bytes\n",
            "None\n",
            "Key error: 'status'\n",
            "Verify that all required columns are present in the DataFrame\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pandera as pa\n",
        "import numpy as np\n",
        "\n",
        "# Creating example data with issues\n",
        "data = {\n",
        "    'id': [1, 2, 3, 4, 5],\n",
        "    'name': ['John', 'Maria', 'Peter', None, 'Ana'],\n",
        "    'age': [25, -30, 35, 40, np.nan],\n",
        "    'salary': ['5000', '6000', '7000', '8000', '9000'],\n",
        "    'email': ['john@email.com', 'maria@email', 'peter@email.com', None, 'ana@email.com'],\n",
        "    'department': ['IT', 'HR', 'Sales', 'IT', None]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Defining validation schema\n",
        "schema = pa.DataFrameSchema({\n",
        "    'id': pa.Column(int, checks=pa.Check.gt(0)),\n",
        "    'name': pa.Column(str, nullable=False),\n",
        "    'age': pa.Column(int, checks=pa.Check.ge(0)),\n",
        "    'salary': pa.Column(float, checks=pa.Check.gt(0)),\n",
        "    'email': pa.Column(str, checks=pa.Check.str_matches(r'^[^@]+@[^@]+\\.[^@]+$'), nullable=True),\n",
        "    'department': pa.Column(str, checks=pa.Check.isin(['IT', 'HR', 'Sales', 'Finance']), nullable=True)\n",
        "})\n",
        "\n",
        "# Applying correction pipeline\n",
        "try:\n",
        "    df_corrected = validation_correction_pipeline(df)\n",
        "\n",
        "    # Checking results\n",
        "    print(\"\\nData after correction:\")\n",
        "    print(df_corrected)\n",
        "\n",
        "except KeyError as e:\n",
        "    print(f\"Key error: {e}\")\n",
        "    print(\"Verify that all required columns are present in the DataFrame\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f867bc5",
      "metadata": {},
      "source": [
        "# Best Practices for Data Correction\n",
        "\n",
        "1. **Document Changes:** Keep a record of all corrections performed.\n",
        "2. **Preserve Original Data:** Always work with copies of the data.\n",
        "3. **Validate After Each Step:** Ensure that corrections do not introduce new issues.\n",
        "4. **Use Quality Metrics:** Define and monitor data quality metrics.\n",
        "5. **Automate the Process:** Create reproducible pipelines for validation and correction.\n",
        "\n",
        "---\n",
        "\n",
        "# Handling Special Cases\n",
        "\n",
        "1. **Sensitive Data:** Be careful when correcting personal or sensitive information.\n",
        "2. **Temporal Data:** Consider seasonality and temporal trends.\n",
        "3. **Categorical Data:** Maintain consistency across categories.\n",
        "4. **Relational Data:** Preserve referential integrity across tables.\n",
        "5. **Batch Data:** Implement efficient strategies for large-scale data processing.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
